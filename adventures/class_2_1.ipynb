{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e39746-928b-4997-bafa-01ca7510d832",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670cbe6a-2be0-4414-afaa-ad18fc086d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display shows: New message\n",
      "Speaker plays: Ding!\n"
     ]
    }
   ],
   "source": [
    "class Display:\n",
    "    def show_message(self, message):\n",
    "        print(f\"Display shows: {message}\")\n",
    "\n",
    "class Speaker:\n",
    "    def play_sound(self, sound):\n",
    "        print(f\"Speaker plays: {sound}\")\n",
    "\n",
    "class Smartphone:\n",
    "    def __init__(self):\n",
    "        self.display = Display()\n",
    "        self.speaker = Speaker()\n",
    "    \n",
    "    def notification(self, message, sound):\n",
    "        self.display.show_message(message)\n",
    "        self.speaker.play_sound(sound)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    phone = Smartphone()\n",
    "    phone.notification(\"New message\", \"Ding!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c9ed5-d629-41cf-be66-dc5bad5d159e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9e451b-92d4-4d34-b187-5d6c9e7751ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Creating user with data: {'name': 'Alice', 'email': 'alice@example.com'}\n",
      "Saving data: {'name': 'Alice', 'email': 'alice@example.com'}\n",
      "LOG: Finding user with ID: 42\n",
      "Retrieving data for query: user_id=42\n",
      "Found: Results for user_id=42\n"
     ]
    }
   ],
   "source": [
    "class Database:\n",
    "    def save_data(self, data):\n",
    "        print(f\"Saving data: {data}\")\n",
    "    \n",
    "    def retrieve_data(self, query):\n",
    "        print(f\"Retrieving data for query: {query}\")\n",
    "        return f\"Results for {query}\"\n",
    "\n",
    "class Logger:\n",
    "    def log(self, message):\n",
    "        print(f\"LOG: {message}\")\n",
    "\n",
    "class UserService:\n",
    "    def __init__(self):\n",
    "        self.database = Database()\n",
    "        self.logger = Logger()\n",
    "    \n",
    "    def create_user(self, user_data):\n",
    "        self.logger.log(f\"Creating user with data: {user_data}\")\n",
    "        self.database.save_data(user_data)\n",
    "        \n",
    "    def find_user(self, user_id):\n",
    "        self.logger.log(f\"Finding user with ID: {user_id}\")\n",
    "        return self.database.retrieve_data(f\"user_id={user_id}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_service = UserService()\n",
    "    user_service.create_user({\"name\": \"Alice\", \"email\": \"alice@example.com\"})\n",
    "    result = user_service.find_user(42)\n",
    "    print(f\"Found: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab97207-dba3-4261-b36f-c6fb615b6b4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d5ab7c-1a72-49b6-b83f-8d3d3e9a0566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New order: Laptop\n",
      "Processing payment of $999.99\n",
      "Shipping to New York costs $11.25\n",
      "Shipping Laptop to New York\n",
      "Order completed! Total cost: $1011.24\n"
     ]
    }
   ],
   "source": [
    "class PaymentProcessor:\n",
    "    def process_payment(self, amount):\n",
    "        print(f\"Processing payment of ${amount}\")\n",
    "        return True\n",
    "\n",
    "class ShippingService:\n",
    "    def calculate_shipping(self, weight, destination):\n",
    "        shipping_cost = weight * 2.5\n",
    "        print(f\"Shipping to {destination} costs ${shipping_cost}\")\n",
    "        return shipping_cost\n",
    "    \n",
    "    def ship(self, product, destination):\n",
    "        print(f\"Shipping {product} to {destination}\")\n",
    "\n",
    "class OrderManager:\n",
    "    def __init__(self):\n",
    "        self.payment_processor = PaymentProcessor()\n",
    "        self.shipping_service = ShippingService()\n",
    "    \n",
    "    def place_order(self, product, price, weight, destination):\n",
    "        print(f\"New order: {product}\")\n",
    "        \n",
    "        # Handle payment\n",
    "        payment_success = self.payment_processor.process_payment(price)\n",
    "        \n",
    "        if payment_success:\n",
    "            # Calculate shipping\n",
    "            shipping_cost = self.shipping_service.calculate_shipping(weight, destination)\n",
    "            \n",
    "            # Ship the product\n",
    "            self.shipping_service.ship(product, destination)\n",
    "            \n",
    "            total_cost = price + shipping_cost\n",
    "            print(f\"Order completed! Total cost: ${total_cost}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Order failed: Payment unsuccessful\")\n",
    "            return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    order_manager = OrderManager()\n",
    "    order_manager.place_order(\"Laptop\", 999.99, 4.5, \"New York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fa624-f69c-4972-9e25-37bce41bd586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d0515f-cd99-4f15-a150-24fc0511c813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notification for user: John Doe\n",
      "Sending email to john@example.com\n",
      "Subject: New Notification\n",
      "Content: Your package has shipped!\n",
      "Sending SMS to 555-123-4567\n",
      "Message: Your package has shipped!\n"
     ]
    }
   ],
   "source": [
    "class EmailSender:\n",
    "    def send_email(self, to_address, subject, content):\n",
    "        print(f\"Sending email to {to_address}\")\n",
    "        print(f\"Subject: {subject}\")\n",
    "        print(f\"Content: {content}\")\n",
    "\n",
    "class SMSSender:\n",
    "    def send_sms(self, phone_number, message):\n",
    "        print(f\"Sending SMS to {phone_number}\")\n",
    "        print(f\"Message: {message}\")\n",
    "\n",
    "class NotificationManager:\n",
    "    def __init__(self):\n",
    "        self.email_sender = EmailSender()\n",
    "        self.sms_sender = SMSSender()\n",
    "    \n",
    "    def notify_user(self, user, notification_type, message):\n",
    "        print(f\"Notification for user: {user['name']}\")\n",
    "        \n",
    "        if notification_type == \"email\" and \"email\" in user:\n",
    "            self.email_sender.send_email(\n",
    "                user[\"email\"], \n",
    "                \"New Notification\", \n",
    "                message\n",
    "            )\n",
    "        elif notification_type == \"sms\" and \"phone\" in user:\n",
    "            self.sms_sender.send_sms(\n",
    "                user[\"phone\"], \n",
    "                message\n",
    "            )\n",
    "        elif notification_type == \"both\":\n",
    "            if \"email\" in user:\n",
    "                self.email_sender.send_email(\n",
    "                    user[\"email\"], \n",
    "                    \"New Notification\", \n",
    "                    message\n",
    "                )\n",
    "            if \"phone\" in user:\n",
    "                self.sms_sender.send_sms(\n",
    "                    user[\"phone\"], \n",
    "                    message\n",
    "                )\n",
    "        else:\n",
    "            print(\"Could not send notification: Missing contact information\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_info = {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"email\": \"john@example.com\",\n",
    "        \"phone\": \"555-123-4567\"\n",
    "    }\n",
    "    \n",
    "    notification = NotificationManager()\n",
    "    notification.notify_user(user_info, \"both\", \"Your package has shipped!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17680e77-1608-4908-9f2d-0760696a5061",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39c7eb4-476e-4e2f-bf8c-68fdd10155dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving secure file: secret.txt\n",
      "Encrypting data: This is co...\n",
      "Saving 43 bytes to file: secret.txt\n",
      "Loading secure file: secret.txt\n",
      "Loading data from file: secret.txt\n",
      "Decrypting data: Data from secre...\n",
      "Loaded content: secret.tx\n"
     ]
    }
   ],
   "source": [
    "class FileStorage:\n",
    "    def save(self, file_name, data):\n",
    "        print(f\"Saving {len(data)} bytes to file: {file_name}\")\n",
    "    \n",
    "    def load(self, file_name):\n",
    "        print(f\"Loading data from file: {file_name}\")\n",
    "        return f\"Data from {file_name}\"\n",
    "\n",
    "class Encryptor:\n",
    "    def encrypt(self, data):\n",
    "        print(f\"Encrypting data: {data[:10]}...\")\n",
    "        return f\"ENCRYPTED({data})\"\n",
    "    \n",
    "    def decrypt(self, encrypted_data):\n",
    "        print(f\"Decrypting data: {encrypted_data[:15]}...\")\n",
    "        # Extract original data from inside ENCRYPTED()\n",
    "        return encrypted_data[10:-1]\n",
    "\n",
    "class SecureFileManager:\n",
    "    def __init__(self):\n",
    "        self.storage = FileStorage()\n",
    "        self.encryptor = Encryptor()\n",
    "    \n",
    "    def save_secure_file(self, file_name, data):\n",
    "        print(f\"Saving secure file: {file_name}\")\n",
    "        \n",
    "        # First encrypt the data\n",
    "        encrypted_data = self.encryptor.encrypt(data)\n",
    "        \n",
    "        # Then store the encrypted data\n",
    "        self.storage.save(file_name, encrypted_data)\n",
    "    \n",
    "    def load_secure_file(self, file_name):\n",
    "        print(f\"Loading secure file: {file_name}\")\n",
    "        \n",
    "        # First load the encrypted data\n",
    "        encrypted_data = self.storage.load(file_name)\n",
    "        \n",
    "        # Then decrypt it\n",
    "        decrypted_data = self.encryptor.decrypt(encrypted_data)\n",
    "        \n",
    "        return decrypted_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    manager = SecureFileManager()\n",
    "    manager.save_secure_file(\"secret.txt\", \"This is confidential information\")\n",
    "    content = manager.load_secure_file(\"secret.txt\")\n",
    "    print(f\"Loaded content: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558a98e-758b-4a79-90d9-9fdf8be006cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3344f2d9-12e9-4771-98fe-ed7f16299bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report: quarterly_sales\n",
      "Analyzing data with 8 entries\n",
      "Creating bar chart with 8 data points\n",
      "Creating line chart with 8 data points\n",
      "Exporting chart to quarterly_sales_bar.png\n",
      "Exporting chart to quarterly_sales_line.png\n",
      "Report completed with 2 visualizations\n",
      "Report summary: {'name': 'quarterly_sales', 'analysis': {'average': 50.625, 'max': 90, 'min': 12}, 'charts': ['quarterly_sales_bar.png', 'quarterly_sales_line.png']}\n"
     ]
    }
   ],
   "source": [
    "class DataAnalyzer:\n",
    "    def analyze(self, data):\n",
    "        print(f\"Analyzing data with {len(data)} entries\")\n",
    "        return {\"average\": sum(data) / len(data), \"max\": max(data), \"min\": min(data)}\n",
    "\n",
    "class DataVisualizer:\n",
    "    def create_chart(self, data, chart_type):\n",
    "        print(f\"Creating {chart_type} chart with {len(data)} data points\")\n",
    "        return f\"{chart_type} chart created\"\n",
    "    \n",
    "    def export_image(self, chart, file_name):\n",
    "        print(f\"Exporting chart to {file_name}\")\n",
    "        return True\n",
    "\n",
    "class ReportGenerator:\n",
    "    def __init__(self):\n",
    "        self.analyzer = DataAnalyzer()\n",
    "        self.visualizer = DataVisualizer()\n",
    "    \n",
    "    def generate_report(self, data, report_name):\n",
    "        print(f\"Generating report: {report_name}\")\n",
    "        \n",
    "        # Analyze the data\n",
    "        analysis_results = self.analyzer.analyze(data)\n",
    "        \n",
    "        # Create visualizations\n",
    "        bar_chart = self.visualizer.create_chart(data, \"bar\")\n",
    "        line_chart = self.visualizer.create_chart(data, \"line\")\n",
    "        \n",
    "        # Export the charts\n",
    "        self.visualizer.export_image(bar_chart, f\"{report_name}_bar.png\")\n",
    "        self.visualizer.export_image(line_chart, f\"{report_name}_line.png\")\n",
    "        \n",
    "        # Compile report summary\n",
    "        report = {\n",
    "            \"name\": report_name,\n",
    "            \"analysis\": analysis_results,\n",
    "            \"charts\": [f\"{report_name}_bar.png\", f\"{report_name}_line.png\"]\n",
    "        }\n",
    "        \n",
    "        print(f\"Report completed with {len(report['charts'])} visualizations\")\n",
    "        return report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_data = [12, 34, 56, 78, 90, 23, 45, 67]\n",
    "    report_gen = ReportGenerator()\n",
    "    report = report_gen.generate_report(sample_data, \"quarterly_sales\")\n",
    "    print(f\"Report summary: {report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c982306-fe78-4ae3-8901-de581a3c98e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cbfa9fa-dedb-418e-902e-e1dd60fa21a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response: ApiResponse(success=True, data=['item1', 'item2'], error=None)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import logging\n",
    "\n",
    "\n",
    "class ConfigManager:\n",
    "    def __init__(self, config_path: str):\n",
    "        self.config_path = config_path\n",
    "        self.settings: Dict = {\"default_timeout\": 30, \"retry_attempts\": 3}\n",
    "        \n",
    "    def get_setting(self, key: str) -> Optional[object]:\n",
    "        return self.settings.get(key)\n",
    "\n",
    "\n",
    "class RequestHandler:\n",
    "    def __init__(self, base_url: str):\n",
    "        self.base_url = base_url\n",
    "        self.logger = logging.getLogger(\"requests\")\n",
    "        \n",
    "    def fetch_data(self, endpoint: str) -> Dict:\n",
    "        self.logger.info(f\"Fetching data from {endpoint}\")\n",
    "        # In real code, this would use requests or httpx\n",
    "        return {\"status\": \"success\", \"data\": [\"item1\", \"item2\"]}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ApiResponse:\n",
    "    success: bool\n",
    "    data: Optional[List] = None\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "class ApiClient:\n",
    "    def __init__(self, api_url: str, config_file: str = \"config.json\"):\n",
    "        # Compose functionality through contained objects\n",
    "        self.config = ConfigManager(config_file)\n",
    "        self.requester = RequestHandler(api_url)\n",
    "        self.logger = logging.getLogger(\"api_client\")\n",
    "    \n",
    "    def get_resources(self, resource_type: str) -> ApiResponse:\n",
    "        timeout = self.config.get_setting(\"default_timeout\")\n",
    "        self.logger.debug(f\"Using timeout of {timeout}s\")\n",
    "        \n",
    "        try:\n",
    "            endpoint = f\"/api/{resource_type}\"\n",
    "            result = self.requester.fetch_data(endpoint)\n",
    "            return ApiResponse(success=True, data=result.get(\"data\"))\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to fetch {resource_type}: {str(e)}\")\n",
    "            return ApiResponse(success=False, error=str(e))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = ApiClient(\"https://api.example.com\")\n",
    "    response = client.get_resources(\"users\")\n",
    "    print(f\"API Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc71152-d64e-4f4c-8a12-fc87fb83f17b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9718a8b3-48ec-4fc2-9c6a-3da045162e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIT: User system performed create_user\n",
      "Details: {\n",
      "  \"username\": \"johndoe\",\n",
      "  \"email\": \"john@example.com\",\n",
      "  \"phone\": \"555-123-4567\"\n",
      "}\n",
      "Sending email to john@example.com\n",
      "Subject: Welcome to our platform!\n",
      "Message: Hello johndoe, your account has been created successfully.\n",
      "User creation result: {'success': True, 'user': {'username': 'johndoe', 'email': 'john@example.com', 'phone': '555-123-4567'}}\n",
      "User activity: [{'timestamp': '2025-04-12T05:08:35.754239', 'type': 'user_created', 'user': 'johndoe'}]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "class EventStore:\n",
    "    def __init__(self, store_path: str = \"events.json\"):\n",
    "        self.store_path = store_path\n",
    "        self.events: List[Dict] = []\n",
    "    \n",
    "    def add_event(self, event_data: Dict) -> bool:\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        self.events.append({\"timestamp\": timestamp, **event_data})\n",
    "        return True\n",
    "    \n",
    "    def query_events(self, event_type: Optional[str] = None) -> List[Dict]:\n",
    "        if event_type:\n",
    "            return [e for e in self.events if e.get(\"type\") == event_type]\n",
    "        return self.events\n",
    "\n",
    "\n",
    "class NotificationSender:\n",
    "    def send_email(self, recipient: str, subject: str, message: str) -> bool:\n",
    "        print(f\"Sending email to {recipient}\")\n",
    "        print(f\"Subject: {subject}\")\n",
    "        print(f\"Message: {message}\")\n",
    "        return True\n",
    "    \n",
    "    def send_sms(self, phone: str, message: str) -> bool:\n",
    "        print(f\"Sending SMS to {phone}\")\n",
    "        print(f\"Message: {message}\")\n",
    "        return True\n",
    "\n",
    "\n",
    "class AuditLogger:\n",
    "    def log_action(self, user: str, action: str, details: Dict) -> None:\n",
    "        print(f\"AUDIT: User {user} performed {action}\")\n",
    "        print(f\"Details: {json.dumps(details, indent=2)}\")\n",
    "\n",
    "\n",
    "class UserManager:\n",
    "    def __init__(self):\n",
    "        # Compose functionality through contained objects\n",
    "        self.event_store = EventStore()\n",
    "        self.notifier = NotificationSender()\n",
    "        self.audit = AuditLogger()\n",
    "    \n",
    "    def create_user(self, username: str, email: str, phone: str) -> Dict:\n",
    "        user_data = {\"username\": username, \"email\": email, \"phone\": phone}\n",
    "        \n",
    "        # Log event\n",
    "        self.event_store.add_event({\n",
    "            \"type\": \"user_created\",\n",
    "            \"user\": username\n",
    "        })\n",
    "        \n",
    "        # Audit logging\n",
    "        self.audit.log_action(\"system\", \"create_user\", user_data)\n",
    "        \n",
    "        # Send welcome notification\n",
    "        self.notifier.send_email(\n",
    "            email, \n",
    "            \"Welcome to our platform!\", \n",
    "            f\"Hello {username}, your account has been created successfully.\"\n",
    "        )\n",
    "        \n",
    "        return {\"success\": True, \"user\": user_data}\n",
    "    \n",
    "    def get_user_activity(self, username: str) -> List[Dict]:\n",
    "        events = self.event_store.query_events()\n",
    "        return [e for e in events if e.get(\"user\") == username]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_mgr = UserManager()\n",
    "    result = user_mgr.create_user(\"johndoe\", \"john@example.com\", \"555-123-4567\")\n",
    "    print(f\"User creation result: {result}\")\n",
    "    \n",
    "    # Check activity\n",
    "    activity = user_mgr.get_user_activity(\"johndoe\")\n",
    "    print(f\"User activity: {activity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c26c8-9468-4ad5-9bd0-96ed4b123c81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2726baf9-bd58-4ef0-86e9-ca9d27b21719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-12 05:11:15 [INFO] Starting pipeline with 3 items\n",
      "2025-04-12 05:11:15 [INFO] Pipeline completed in 0.00 seconds\n",
      "\n",
      "Processed data:\n",
      "  {'id': 1, 'name': 'APPLE', 'category': 'FRUIT'}\n",
      "  {'id': 2, 'name': 'BANANA', 'category': 'FRUIT'}\n",
      "  {'id': 3, 'name': 'CARROT', 'category': 'VEGETABLE'}\n",
      "\n",
      "Pipeline statistics:\n",
      "  {'metrics': {'pipeline_runs': 1, 'items_processed': 3}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import Dict, List, Any, Optional\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class LogLevel(Enum):\n",
    "    DEBUG = 1\n",
    "    INFO = 2\n",
    "    WARNING = 3\n",
    "    ERROR = 4\n",
    "\n",
    "\n",
    "class MetricsCollector:\n",
    "    def __init__(self):\n",
    "        self.metrics: Dict[str, int] = {}\n",
    "    \n",
    "    def increment(self, metric_name: str, value: int = 1) -> None:\n",
    "        if metric_name not in self.metrics:\n",
    "            self.metrics[metric_name] = 0\n",
    "        self.metrics[metric_name] += value\n",
    "    \n",
    "    def get_metrics(self) -> Dict[str, int]:\n",
    "        return self.metrics.copy()\n",
    "\n",
    "\n",
    "class SimpleLogger:\n",
    "    def __init__(self, min_level: LogLevel = LogLevel.INFO):\n",
    "        self.min_level = min_level\n",
    "    \n",
    "    def log(self, level: LogLevel, message: str) -> None:\n",
    "        if level.value >= self.min_level.value:\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"{timestamp} [{level.name}] {message}\")\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    def process(self, data: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Process a list of data items.\"\"\"\n",
    "        return [self._transform_item(item) for item in data]\n",
    "    \n",
    "    def _transform_item(self, item: Dict) -> Dict:\n",
    "        \"\"\"Transform a single data item.\"\"\"\n",
    "        return {k: v.upper() if isinstance(v, str) else v for k, v in item.items()}\n",
    "\n",
    "\n",
    "class DataPipeline:\n",
    "    def __init__(self):\n",
    "        # Using composition to include logging, metrics, and processing\n",
    "        self.logger = SimpleLogger(LogLevel.INFO)\n",
    "        self.metrics = MetricsCollector()\n",
    "        self.processor = DataProcessor()\n",
    "    \n",
    "    def run_pipeline(self, input_data: List[Dict]) -> List[Dict]:\n",
    "        self.logger.log(LogLevel.INFO, f\"Starting pipeline with {len(input_data)} items\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process the data\n",
    "        try:\n",
    "            self.metrics.increment(\"pipeline_runs\")\n",
    "            self.metrics.increment(\"items_processed\", len(input_data))\n",
    "            \n",
    "            result = self.processor.process(input_data)\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            self.logger.log(LogLevel.INFO, f\"Pipeline completed in {elapsed:.2f} seconds\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log(LogLevel.ERROR, f\"Pipeline error: {str(e)}\")\n",
    "            self.metrics.increment(\"pipeline_errors\")\n",
    "            raise\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"metrics\": self.metrics.get_metrics()\n",
    "        }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data\n",
    "    sample_data = [\n",
    "        {\"id\": 1, \"name\": \"apple\", \"category\": \"fruit\"},\n",
    "        {\"id\": 2, \"name\": \"banana\", \"category\": \"fruit\"},\n",
    "        {\"id\": 3, \"name\": \"carrot\", \"category\": \"vegetable\"}\n",
    "    ]\n",
    "    \n",
    "    # Create and run the pipeline\n",
    "    pipeline = DataPipeline()\n",
    "    processed_data = pipeline.run_pipeline(sample_data)\n",
    "    \n",
    "    print(\"\\nProcessed data:\")\n",
    "    for item in processed_data:\n",
    "        print(f\"  {item}\")\n",
    "    \n",
    "    print(\"\\nPipeline statistics:\")\n",
    "    stats = pipeline.get_statistics()\n",
    "    print(f\"  {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b6fd7-72dc-4162-b85d-5fb4f5ceb824",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "282acdeb-5107-420a-ab74-b618bbe4eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing credit card payment for $100.50\n",
      "Payment successful: True\n"
     ]
    }
   ],
   "source": [
    "from typing import Protocol, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class PaymentMethod(Protocol):\n",
    "    def process_payment(self, amount: float) -> bool:\n",
    "        ...\n",
    "\n",
    "class CreditCardPayment:\n",
    "    def process_payment(self, amount: float) -> bool:\n",
    "        print(f\"Processing credit card payment for ${amount:.2f}\")\n",
    "        return True\n",
    "\n",
    "class PayPalPayment:\n",
    "    def process_payment(self, amount: float) -> bool:\n",
    "        print(f\"Processing PayPal payment for ${amount:.2f}\")\n",
    "        return True\n",
    "\n",
    "@dataclass\n",
    "class PaymentProcessor:\n",
    "    payment_methods: List[PaymentMethod]\n",
    "    \n",
    "    def process(self, amount: float) -> bool:\n",
    "        for method in self.payment_methods:\n",
    "            if method.process_payment(amount):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    payment_methods = [CreditCardPayment(), PayPalPayment()]\n",
    "    processor = PaymentProcessor(payment_methods)\n",
    "    \n",
    "    result = processor.process(100.50)\n",
    "    print(f\"Payment successful: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fccd6b-8da1-46ca-9a40-a96cb4580d3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d07087-2bd7-4d35-a27e-2eae39b983a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StatsD] Incrementing cache.attempt with tags {'key': 'some_key'}\n",
      "[Redis] GET some_key\n",
      "[Memory] GET some_key\n",
      "[StatsD] Incrementing cache.miss with tags None\n",
      "[Redis] SET important (TTL: 0:05:00)\n",
      "[Memory] SET important (TTL: 0:05:00)\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Dict, Any\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Interfaces\n",
    "class CacheStorage(ABC):\n",
    "    @abstractmethod\n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def set(self, key: str, value: Any, ttl: Optional[timedelta] = None) -> None:\n",
    "        pass\n",
    "\n",
    "class MetricsProvider(ABC):\n",
    "    @abstractmethod\n",
    "    def increment(self, metric: str, tags: Dict[str, str] = None) -> None:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class RedisStorage(CacheStorage):\n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        print(f\"[Redis] GET {key}\")\n",
    "        # Actual implementation would use redis-py client\n",
    "        return json.loads('{\"mock\": \"data\"}') if key == \"valid\" else None\n",
    "    \n",
    "    def set(self, key: str, value: Any, ttl: Optional[timedelta] = None) -> None:\n",
    "        print(f\"[Redis] SET {key} (TTL: {ttl})\")\n",
    "\n",
    "class MemoryStorage(CacheStorage):\n",
    "    def __init__(self):\n",
    "        self._store: Dict[str, Any] = {}\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        print(f\"[Memory] GET {key}\")\n",
    "        return self._store.get(key)\n",
    "    \n",
    "    def set(self, key: str, value: Any, ttl: Optional[timedelta] = None) -> None:\n",
    "        print(f\"[Memory] SET {key} (TTL: {ttl})\")\n",
    "        self._store[key] = value\n",
    "\n",
    "class StatsDMetrics(MetricsProvider):\n",
    "    def increment(self, metric: str, tags: Dict[str, str] = None) -> None:\n",
    "        print(f\"[StatsD] Incrementing {metric} with tags {tags}\")\n",
    "\n",
    "# Composed Cache Service\n",
    "class CacheService:\n",
    "    def __init__(\n",
    "        self,\n",
    "        storage: CacheStorage,\n",
    "        metrics: MetricsProvider,\n",
    "        fallback_storage: Optional[CacheStorage] = None\n",
    "    ):\n",
    "        self._primary = storage\n",
    "        self._fallback = fallback_storage\n",
    "        self._metrics = metrics\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        try:\n",
    "            self._metrics.increment(\"cache.attempt\", {\"key\": key})\n",
    "            value = self._primary.get(key)\n",
    "            \n",
    "            if value is None and self._fallback:\n",
    "                value = self._fallback.get(key)\n",
    "                if value:\n",
    "                    self._metrics.increment(\"cache.fallback_hit\")\n",
    "            \n",
    "            if value:\n",
    "                self._metrics.increment(\"cache.hit\")\n",
    "            else:\n",
    "                self._metrics.increment(\"cache.miss\")\n",
    "            \n",
    "            return value\n",
    "        except Exception as e:\n",
    "            self._metrics.increment(\"cache.error\", {\"error\": str(e)})\n",
    "            raise\n",
    "\n",
    "    def set(self, key: str, value: Any, ttl: Optional[timedelta] = None) -> None:\n",
    "        self._primary.set(key, value, ttl)\n",
    "        if self._fallback:\n",
    "            self._fallback.set(key, value, ttl)\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    redis = RedisStorage()\n",
    "    memory = MemoryStorage()\n",
    "    metrics = StatsDMetrics()\n",
    "    \n",
    "    cache = CacheService(\n",
    "        storage=redis,\n",
    "        fallback_storage=memory,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    # Will use Redis -> fallback to Memory\n",
    "    data = cache.get(\"some_key\")\n",
    "    cache.set(\"important\", {\"data\": 123}, timedelta(minutes=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70fe42-600f-4dfb-9e49-5d85263c9497",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7735e6aa-fab3-4bce-9bae-1bacb52f70f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call: {'id': '123', 'data': 'mock_response'}\n",
      "[INFO] Cache hit for https://mock-api.example.com/resources/123\n",
      "Cached call: {'id': '123', 'data': 'mock_response'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from typing import Optional, Callable, Any, Dict, Protocol\n",
    "from unittest.mock import MagicMock\n",
    "import time\n",
    "\n",
    "# Mock server setup - This replaces the real API call\n",
    "requests.get = MagicMock(return_value=MagicMock(\n",
    "    status_code=200,\n",
    "    json=lambda: {\"id\": \"123\", \"data\": \"mock_response\"}\n",
    "))\n",
    "\n",
    "# Interfaces\n",
    "class Logger(Protocol):\n",
    "    def log(self, message: str, level: str = \"INFO\") -> None: ...\n",
    "\n",
    "class Cache(Protocol):\n",
    "    def get(self, key: str) -> Optional[Any]: ...\n",
    "    def set(self, key: str, value: Any, ttl: int = 0) -> None: ...\n",
    "\n",
    "# Implementations\n",
    "class ConsoleLogger:\n",
    "    def log(self, message: str, level: str = \"INFO\") -> None:\n",
    "        print(f\"[{level}] {message}\")\n",
    "\n",
    "class MemoryCache:\n",
    "    def __init__(self):\n",
    "        self._store = {}\n",
    "    \n",
    "    def get(self, key: str) -> Optional[Any]:\n",
    "        return self._store.get(key)\n",
    "    \n",
    "    def set(self, key: str, value: Any, ttl: int = 0) -> None:\n",
    "        self._store[key] = value\n",
    "\n",
    "# API Client with Composition\n",
    "class JsonApiClient:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url: str,\n",
    "        retry_strategy: Optional[Callable[[int], float]] = None,\n",
    "        logger: Optional[Logger] = None,\n",
    "        cache: Optional[Cache] = None\n",
    "    ):\n",
    "        self.base_url = base_url\n",
    "        self.retry = retry_strategy or self._default_retry\n",
    "        self.logger = logger\n",
    "        self.cache = cache\n",
    "\n",
    "    def _default_retry(self, attempt: int) -> float:\n",
    "        return min(2 ** attempt, 5)\n",
    "\n",
    "    def get_resource(self, resource_id: str) -> Dict[str, Any]:\n",
    "        cache_key = f\"{self.base_url}/resources/{resource_id}\"\n",
    "        \n",
    "        if self.cache and (cached := self.cache.get(cache_key)):\n",
    "            if self.logger:\n",
    "                self.logger.log(f\"Cache hit for {cache_key}\")\n",
    "            return cached\n",
    "\n",
    "        attempt = 0\n",
    "        while True:\n",
    "            attempt += 1\n",
    "            try:\n",
    "                response = requests.get(f\"{self.base_url}/resources/{resource_id}\")\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                if self.cache:\n",
    "                    self.cache.set(cache_key, data, ttl=300)\n",
    "                \n",
    "                return data\n",
    "            except Exception as e:\n",
    "                if attempt >= 3:\n",
    "                    if self.logger:\n",
    "                        self.logger.log(f\"Final failure after {attempt} attempts\", \"ERROR\")\n",
    "                    raise\n",
    "                \n",
    "                delay = self.retry(attempt)\n",
    "                if self.logger:\n",
    "                    self.logger.log(f\"Retry #{attempt} after {delay}s: {str(e)}\", \"WARNING\")\n",
    "                time.sleep(delay)\n",
    "\n",
    "# Working Example\n",
    "if __name__ == \"__main__\":\n",
    "    client = JsonApiClient(\n",
    "        base_url=\"https://mock-api.example.com\",\n",
    "        logger=ConsoleLogger(),\n",
    "        cache=MemoryCache(),\n",
    "        retry_strategy=lambda attempt: attempt * 0.1  # Shorter delays for demo\n",
    "    )\n",
    "\n",
    "    # First call - hits the mock API\n",
    "    print(\"First call:\", client.get_resource(\"123\"))\n",
    "    \n",
    "    # Second call - returns cached result\n",
    "    print(\"Cached call:\", client.get_resource(\"123\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49ea07-d920-4869-ba12-67b7811a8991",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3d601b7-b85b-42b3-9d1b-719d4255a2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending email to user@example.com: Welcome to our service!\n",
      "[Analytics] notification_sent: {'channel': 'EmailChannel', 'recipient': 'user@example.com', 'success': True}\n",
      "Sending SMS to +1234567890: Your verification code is 1234...\n",
      "[Analytics] notification_sent: {'channel': 'SMSChannel', 'recipient': '+1234567890', 'success': True}\n",
      "Sending email to user@example.com: Reminder: Your subscription is expiring\n",
      "[Analytics] notification_sent: {'channel': 'EmailChannel', 'recipient': 'user@example.com', 'success': True}\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "\n",
    "# Interfaces\n",
    "class NotificationChannel(ABC):\n",
    "    @abstractmethod\n",
    "    def send(self, recipient: str, message: str) -> bool:\n",
    "        pass\n",
    "\n",
    "class AnalyticsTracker(ABC):\n",
    "    @abstractmethod\n",
    "    def track_event(self, event_name: str, metadata: Dict[str, Any]) -> None:\n",
    "        pass\n",
    "\n",
    "class RateLimiter(ABC):\n",
    "    @abstractmethod\n",
    "    def check_limit(self, key: str) -> bool:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class EmailChannel(NotificationChannel):\n",
    "    def send(self, recipient: str, message: str) -> bool:\n",
    "        print(f\"Sending email to {recipient}: {message}\")\n",
    "        return True\n",
    "\n",
    "class SMSChannel(NotificationChannel):\n",
    "    def send(self, recipient: str, message: str) -> bool:\n",
    "        print(f\"Sending SMS to {recipient}: {message[:30]}...\")\n",
    "        return True\n",
    "\n",
    "class GoogleAnalyticsTracker(AnalyticsTracker):\n",
    "    def track_event(self, event_name: str, metadata: Dict[str, Any]) -> None:\n",
    "        print(f\"[Analytics] {event_name}: {metadata}\")\n",
    "\n",
    "class SlidingWindowRateLimiter(RateLimiter):\n",
    "    def __init__(self, max_requests: int, window_seconds: int):\n",
    "        self.max_requests = max_requests\n",
    "        self.window = window_seconds\n",
    "        self.requests = {}\n",
    "\n",
    "    def check_limit(self, key: str) -> bool:\n",
    "        current_time = time.time()\n",
    "        if key not in self.requests:\n",
    "            self.requests[key] = []\n",
    "        \n",
    "        # Remove old requests\n",
    "        self.requests[key] = [\n",
    "            t for t in self.requests[key] \n",
    "            if current_time - t < self.window\n",
    "        ]\n",
    "        \n",
    "        if len(self.requests[key]) >= self.max_requests:\n",
    "            return False\n",
    "            \n",
    "        self.requests[key].append(current_time)\n",
    "        return True\n",
    "\n",
    "# Composed Notification Service\n",
    "@dataclass\n",
    "class NotificationService:\n",
    "    channels: List[NotificationChannel]\n",
    "    analytics: AnalyticsTracker\n",
    "    rate_limiter: RateLimiter\n",
    "    default_channel: NotificationChannel = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.default_channel = self.channels[0] if self.channels else None\n",
    "\n",
    "    def send_notification(\n",
    "        self,\n",
    "        recipient: str,\n",
    "        message: str,\n",
    "        channel_type: Optional[str] = None\n",
    "    ) -> bool:\n",
    "        if not self.rate_limiter.check_limit(recipient):\n",
    "            self.analytics.track_event(\"rate_limit_exceeded\", {\"recipient\": recipient})\n",
    "            return False\n",
    "\n",
    "        channel = self.default_channel\n",
    "        if channel_type:\n",
    "            channel = next((c for c in self.channels if c.__class__.__name__.lower().startswith(channel_type)), None)\n",
    "\n",
    "        if not channel:\n",
    "            return False\n",
    "\n",
    "        success = channel.send(recipient, message)\n",
    "        self.analytics.track_event(\n",
    "            \"notification_sent\",\n",
    "            {\n",
    "                \"channel\": channel.__class__.__name__,\n",
    "                \"recipient\": recipient,\n",
    "                \"success\": success\n",
    "            }\n",
    "        )\n",
    "        return success\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure dependencies\n",
    "    email = EmailChannel()\n",
    "    sms = SMSChannel()\n",
    "    analytics = GoogleAnalyticsTracker()\n",
    "    rate_limiter = SlidingWindowRateLimiter(max_requests=2, window_seconds=60)\n",
    "\n",
    "    # Compose the service\n",
    "    notifier = NotificationService(\n",
    "        channels=[email, sms],\n",
    "        analytics=analytics,\n",
    "        rate_limiter=rate_limiter\n",
    "    )\n",
    "\n",
    "    # Send notifications\n",
    "    notifier.send_notification(\"user@example.com\", \"Welcome to our service!\", \"email\")\n",
    "    notifier.send_notification(\"+1234567890\", \"Your verification code is 123456\", \"sms\")\n",
    "    \n",
    "    # This will hit rate limit\n",
    "    notifier.send_notification(\"user@example.com\", \"Reminder: Your subscription is expiring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed5fb6-8802-4c6b-b686-3e903bedd123",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712d61b2-ffa2-47cb-aca2-b142a92e88a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting JSON:\n",
      "Export progress: 100.0%\n",
      "\n",
      "Exporting Compressed CSV:\n",
      "Export progress: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, BinaryIO\n",
    "import zipfile\n",
    "import json\n",
    "import csv\n",
    "from io import StringIO, BytesIO\n",
    "import time\n",
    "\n",
    "# Interfaces\n",
    "class DataFormatter(ABC):\n",
    "    @abstractmethod\n",
    "    def format(self, data: List[Dict]) -> bytes:\n",
    "        pass\n",
    "\n",
    "class CompressionStrategy(ABC):\n",
    "    @abstractmethod\n",
    "    def compress(self, data: bytes) -> bytes:\n",
    "        pass\n",
    "\n",
    "class ProgressTracker(ABC):\n",
    "    @abstractmethod\n",
    "    def update(self, progress: float) -> None:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class JSONFormatter(DataFormatter):\n",
    "    def format(self, data: List[Dict]) -> bytes:\n",
    "        return json.dumps(data, indent=2).encode('utf-8')\n",
    "\n",
    "class CSVFormatter(DataFormatter):\n",
    "    def format(self, data: List[Dict]) -> bytes:\n",
    "        if not data:\n",
    "            return b''\n",
    "        \n",
    "        output = StringIO()\n",
    "        writer = csv.DictWriter(output, fieldnames=data[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "        return output.getvalue().encode('utf-8')\n",
    "\n",
    "class ZIPCompression(CompressionStrategy):\n",
    "    def compress(self, data: bytes) -> bytes:\n",
    "        output = BytesIO()\n",
    "        with zipfile.ZipFile(output, 'w') as zipf:\n",
    "            zipf.writestr('data', data)\n",
    "        return output.getvalue()\n",
    "\n",
    "class ConsoleProgressTracker(ProgressTracker):\n",
    "    def update(self, progress: float) -> None:\n",
    "        print(f\"\\rExport progress: {progress:.1%}\", end='', flush=True)\n",
    "\n",
    "# Composed File Exporter\n",
    "class DataExporter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        formatter: DataFormatter,\n",
    "        compressor: Optional[CompressionStrategy] = None,\n",
    "        progress_tracker: Optional[ProgressTracker] = None\n",
    "    ):\n",
    "        self.formatter = formatter\n",
    "        self.compressor = compressor\n",
    "        self.progress = progress_tracker\n",
    "\n",
    "    def export(self, data: List[Dict], output_stream: BinaryIO) -> None:\n",
    "        total_steps = 3 if self.compressor else 2\n",
    "        current_step = 1\n",
    "        \n",
    "        # Step 1: Format data\n",
    "        if self.progress:\n",
    "            self.progress.update(current_step/total_steps)\n",
    "        formatted = self.formatter.format(data)\n",
    "        current_step += 1\n",
    "        \n",
    "        # Step 2: Compress (if configured)\n",
    "        if self.compressor:\n",
    "            if self.progress:\n",
    "                self.progress.update(current_step/total_steps)\n",
    "            formatted = self.compressor.compress(formatted)\n",
    "            current_step += 1\n",
    "        \n",
    "        # Step 3: Write output\n",
    "        if self.progress:\n",
    "            self.progress.update(1.0)\n",
    "        output_stream.write(formatted)\n",
    "        \n",
    "        if self.progress:\n",
    "            print()  # New line after progress\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data\n",
    "    sales_data = [\n",
    "        {\"id\": 1, \"product\": \"Laptop\", \"amount\": 999.99},\n",
    "        {\"id\": 2, \"product\": \"Mouse\", \"amount\": 19.99},\n",
    "        {\"id\": 3, \"product\": \"Keyboard\", \"amount\": 49.99}\n",
    "    ]\n",
    "\n",
    "    # Configure export options\n",
    "    json_exporter = DataExporter(\n",
    "        formatter=JSONFormatter(),\n",
    "        progress_tracker=ConsoleProgressTracker()\n",
    "    )\n",
    "    \n",
    "    csv_compressed_exporter = DataExporter(\n",
    "        formatter=CSVFormatter(),\n",
    "        compressor=ZIPCompression(),\n",
    "        progress_tracker=ConsoleProgressTracker()\n",
    "    )\n",
    "\n",
    "    # Perform exports\n",
    "    print(\"Exporting JSON:\")\n",
    "    with open('sales.json', 'wb') as f:\n",
    "        json_exporter.export(sales_data, f)\n",
    "    \n",
    "    print(\"\\nExporting Compressed CSV:\")\n",
    "    with open('sales.csv.zip', 'wb') as f:\n",
    "        csv_compressed_exporter.export(sales_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8cdc1f-5360-416c-b335-a5706dcc35b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215aa9d6-e412-48a8-a11e-7675993dd6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from TXT: sample.txt\n",
      "Exporting analysis to Markdown: analysis.md\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Interfaces\n",
    "class TextExtractor(ABC):\n",
    "    @abstractmethod\n",
    "    def extract_text(self, file_path: Path) -> str:\n",
    "        pass\n",
    "\n",
    "class TextAnalyzer(ABC):\n",
    "    @abstractmethod\n",
    "    def analyze(self, text: str) -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "class DocumentExporter(ABC):\n",
    "    @abstractmethod\n",
    "    def export(self, analysis: Dict[str, Any], output_path: Path) -> None:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class PDFExtractor(TextExtractor):\n",
    "    def extract_text(self, file_path: Path) -> str:\n",
    "        print(f\"Extracting text from PDF: {file_path}\")\n",
    "        # In a real implementation, use PyPDF2 or pdfminer\n",
    "        return \"Sample PDF text with keywords: python, composition, OOP\"\n",
    "\n",
    "class TXTExtractor(TextExtractor):\n",
    "    def extract_text(self, file_path: Path) -> str:\n",
    "        print(f\"Extracting text from TXT: {file_path}\")\n",
    "        return file_path.read_text()\n",
    "\n",
    "class KeywordAnalyzer(TextAnalyzer):\n",
    "    def __init__(self, keywords: List[str]):\n",
    "        self.keywords = keywords\n",
    "    \n",
    "    def analyze(self, text: str) -> Dict[str, Any]:\n",
    "        word_counts = {kw: len(re.findall(rf\"\\b{kw}\\b\", text.lower())) \n",
    "                      for kw in self.keywords}\n",
    "        return {\n",
    "            \"word_counts\": word_counts,\n",
    "            \"total_keywords\": sum(word_counts.values())\n",
    "        }\n",
    "\n",
    "class SentimentAnalyzer(TextAnalyzer):\n",
    "    def analyze(self, text: str) -> Dict[str, Any]:\n",
    "        # Simplified sentiment analysis\n",
    "        positive_words = {\"good\", \"excellent\", \"happy\"}\n",
    "        negative_words = {\"bad\", \"poor\", \"unhappy\"}\n",
    "        \n",
    "        pos_count = sum(1 for word in text.lower().split() if word in positive_words)\n",
    "        neg_count = sum(1 for word in text.lower().split() if word in negative_words)\n",
    "        \n",
    "        return {\n",
    "            \"positive_words\": pos_count,\n",
    "            \"negative_words\": neg_count,\n",
    "            \"sentiment\": \"positive\" if pos_count > neg_count else \"negative\"\n",
    "        }\n",
    "\n",
    "class JSONExporter(DocumentExporter):\n",
    "    def export(self, analysis: Dict[str, Any], output_path: Path) -> None:\n",
    "        print(f\"Exporting analysis to JSON: {output_path}\")\n",
    "        output_path.write_text(json.dumps(analysis, indent=2))\n",
    "\n",
    "class MarkdownExporter(DocumentExporter):\n",
    "    def export(self, analysis: Dict[str, Any], output_path: Path) -> None:\n",
    "        print(f\"Exporting analysis to Markdown: {output_path}\")\n",
    "        markdown = \"## Document Analysis\\n\\n\"\n",
    "        markdown += \"\\n\".join(f\"- **{k}**: {v}\" for k, v in analysis.items())\n",
    "        output_path.write_text(markdown)\n",
    "\n",
    "# Composed Document Processor\n",
    "@dataclass\n",
    "class DocumentProcessor:\n",
    "    extractor: TextExtractor\n",
    "    analyzers: List[TextAnalyzer]\n",
    "    exporter: DocumentExporter\n",
    "    \n",
    "    def process(self, input_path: Path, output_path: Path) -> None:\n",
    "        # Step 1: Extract text\n",
    "        text = self.extractor.extract_text(input_path)\n",
    "        \n",
    "        # Step 2: Analyze text\n",
    "        analysis = {}\n",
    "        for analyzer in self.analyzers:\n",
    "            analysis.update(analyzer.analyze(text))\n",
    "        \n",
    "        # Step 3: Export results\n",
    "        self.exporter.export(analysis, output_path)\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample text file\n",
    "    sample_text = Path(\"sample.txt\")\n",
    "    sample_text.write_text(\"This document discusses Python design patterns. \"\n",
    "                         \"Composition over inheritance is a good practice. \"\n",
    "                         \"It makes your code more flexible and maintainable.\")\n",
    "    \n",
    "    # Configure processor\n",
    "    processor = DocumentProcessor(\n",
    "        extractor=TXTExtractor(),\n",
    "        analyzers=[\n",
    "            KeywordAnalyzer([\"python\", \"composition\", \"inheritance\"]),\n",
    "            SentimentAnalyzer()\n",
    "        ],\n",
    "        exporter=MarkdownExporter()\n",
    "    )\n",
    "    \n",
    "    # Process document\n",
    "    processor.process(sample_text, Path(\"analysis.md\"))\n",
    "    \n",
    "    # Clean up\n",
    "    sample_text.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b571be2-cd4b-44d3-884e-5298ca2f358e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20dd3404-b2ea-4c51-a461-2a95e5cc2c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing features...\n",
      "Standardizing features...\n",
      "\n",
      "Model Evaluation Results:\n",
      "accuracy: 0.8900\n",
      "precision: 0.8776\n",
      "recall: 0.8958\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Interfaces\n",
    "class DataPreprocessor(ABC):\n",
    "    @abstractmethod\n",
    "    def preprocess(self, X: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "class Model(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "class Evaluator(ABC):\n",
    "    @abstractmethod\n",
    "    def evaluate(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class StandardScalerPreprocessor(DataPreprocessor):\n",
    "    def preprocess(self, X: np.ndarray) -> np.ndarray:\n",
    "        print(\"Standardizing features...\")\n",
    "        return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "class MinMaxPreprocessor(DataPreprocessor):\n",
    "    def preprocess(self, X: np.ndarray) -> np.ndarray:\n",
    "        print(\"Normalizing features...\")\n",
    "        return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "class LogisticRegressionModel(Model):\n",
    "    def __init__(self, learning_rate: float = 0.01, n_iters: int = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def train(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            linear = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self._sigmoid(linear)\n",
    "            \n",
    "            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / n_samples) * np.sum(predictions - y)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        linear = np.dot(X, self.weights) + self.bias\n",
    "        return (self._sigmoid(linear) > 0.5).astype(int)\n",
    "    \n",
    "    def _sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class ClassificationEvaluator(Evaluator):\n",
    "    def evaluate(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"precision\": self._precision(y_true, y_pred),\n",
    "            \"recall\": self._recall(y_true, y_pred)\n",
    "        }\n",
    "    \n",
    "    def _precision(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        return tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    \n",
    "    def _recall(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        return tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "# Composed ML Pipeline\n",
    "@dataclass\n",
    "class MLPipeline:\n",
    "    preprocessor: DataPreprocessor\n",
    "    model: Model\n",
    "    evaluator: Evaluator\n",
    "    \n",
    "    def run(self, X: np.ndarray, y: np.ndarray, test_size: float = 0.2) -> Dict[str, float]:\n",
    "        # Split data\n",
    "        split_idx = int(len(X) * (1 - test_size))\n",
    "        X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "        X_test, y_test = X[split_idx:], y[split_idx:]\n",
    "        \n",
    "        # Preprocess data\n",
    "        X_train = self.preprocessor.preprocess(X_train)\n",
    "        X_test = self.preprocessor.preprocess(X_test)\n",
    "        \n",
    "        # Train model\n",
    "        self.model.train(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        return self.evaluator.evaluate(y_test, y_pred)\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate synthetic data\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "    \n",
    "    # Configure pipeline\n",
    "    pipeline = MLPipeline(\n",
    "        preprocessor=StandardScalerPreprocessor(),\n",
    "        model=LogisticRegressionModel(learning_rate=0.1, n_iters=2000),\n",
    "        evaluator=ClassificationEvaluator()\n",
    "    )\n",
    "    \n",
    "    # Run pipeline\n",
    "    results = pipeline.run(X, y)\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    for metric, value in results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b43ad-c45a-4c3a-aef9-642134cd1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cc24338-ff9c-4fd4-9388-e6f4dfb13e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running workflow:\n",
      "[2025-04-12T05:45:27.719467][INFO] Workflow started\n",
      "[2025-04-12T05:45:27.719505][INFO] Executing DataFetchTask\n",
      "Fetching data from API...\n",
      "[2025-04-12T05:45:28.721785][INFO] Task completed in 1.00s\n",
      "[2025-04-12T05:45:28.722281][WARNING] Condition failed, aborting workflow\n",
      "[2025-04-12T05:45:28.722388][INFO] Workflow completed\n",
      "\n",
      "Final Context:\n",
      "raw_data: [57, 5, 10, 21, 73]\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any, Optional, List\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Interfaces\n",
    "class Task(ABC):\n",
    "    @abstractmethod\n",
    "    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "class Condition(ABC):\n",
    "    @abstractmethod\n",
    "    def evaluate(self, context: Dict[str, Any]) -> bool:\n",
    "        pass\n",
    "\n",
    "class Logger(ABC):\n",
    "    @abstractmethod\n",
    "    def log(self, message: str, level: str = \"INFO\") -> None:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class DataFetchTask(Task):\n",
    "    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(\"Fetching data from API...\")\n",
    "        time.sleep(1)\n",
    "        return {\"raw_data\": [random.randint(1, 100) for _ in range(5)]}\n",
    "\n",
    "class DataTransformTask(Task):\n",
    "    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(\"Transforming data...\")\n",
    "        raw = context[\"raw_data\"]\n",
    "        return {\n",
    "            \"transformed_data\": [x * 2 for x in raw],\n",
    "            \"stats\": {\n",
    "                \"mean\": sum(raw) / len(raw),\n",
    "                \"max\": max(raw)\n",
    "            }\n",
    "        }\n",
    "\n",
    "class ThresholdCondition(Condition):\n",
    "    def __init__(self, threshold: float):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def evaluate(self, context: Dict[str, Any]) -> bool:\n",
    "        stats = context.get(\"stats\", {})\n",
    "        return stats.get(\"mean\", 0) > self.threshold\n",
    "\n",
    "class ConsoleLogger(Logger):\n",
    "    def log(self, message: str, level: str = \"INFO\") -> None:\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        print(f\"[{timestamp}][{level}] {message}\")\n",
    "\n",
    "# Composed Workflow Engine\n",
    "class WorkflowEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tasks: List[Task],\n",
    "        conditions: Optional[List[Condition]] = None,\n",
    "        logger: Optional[Logger] = None\n",
    "    ):\n",
    "        self.tasks = tasks\n",
    "        self.conditions = conditions or []\n",
    "        self.logger = logger\n",
    "        \n",
    "    def run(self, initial_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "        context = initial_context or {}\n",
    "        \n",
    "        if self.logger:\n",
    "            self.logger.log(\"Workflow started\")\n",
    "        \n",
    "        for task in self.tasks:\n",
    "            try:\n",
    "                if self.logger:\n",
    "                    self.logger.log(f\"Executing {task.__class__.__name__}\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                result = task.execute(context)\n",
    "                context.update(result)\n",
    "                \n",
    "                if self.logger:\n",
    "                    duration = time.time() - start_time\n",
    "                    self.logger.log(f\"Task completed in {duration:.2f}s\")\n",
    "                \n",
    "                # Check conditions after each task\n",
    "                if not all(cond.evaluate(context) for cond in self.conditions):\n",
    "                    if self.logger:\n",
    "                        self.logger.log(\"Condition failed, aborting workflow\", \"WARNING\")\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if self.logger:\n",
    "                    self.logger.log(f\"Task failed: {str(e)}\", \"ERROR\")\n",
    "                raise\n",
    "        \n",
    "        if self.logger:\n",
    "            self.logger.log(\"Workflow completed\")\n",
    "        \n",
    "        return context\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure workflow\n",
    "    engine = WorkflowEngine(\n",
    "        tasks=[\n",
    "            DataFetchTask(),\n",
    "            DataTransformTask()\n",
    "        ],\n",
    "        conditions=[\n",
    "            ThresholdCondition(threshold=30)\n",
    "        ],\n",
    "        logger=ConsoleLogger()\n",
    "    )\n",
    "    \n",
    "    # Execute workflow\n",
    "    print(\"Running workflow:\")\n",
    "    result = engine.run()\n",
    "    \n",
    "    print(\"\\nFinal Context:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096313b6-f48b-4e98-b98b-028db808e703",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66fda783-bcb4-490e-bd1f-a44395c12e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: photo1.jpgAnalyzing dataset: sales_q1\n",
      "\n",
      "Processing image: photo2.png\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Analyzing dataset: inventory\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Task b0c602dc-c730-43a8-a545-3df3a1d3b8cd result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"mean\": 42.5,\n",
      "      \"std_dev\": 3.14\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.365584\n",
      "}\n",
      "Task 7d9d5bf7-9d1b-4dba-8526-3d866e758a9b result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.3675704\n",
      "}\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Task b0c602dc-c730-43a8-a545-3df3a1d3b8cd result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"mean\": 42.5,\n",
      "      \"std_dev\": 3.14\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.365584\n",
      "}\n",
      "Task 7d9d5bf7-9d1b-4dba-8526-3d866e758a9b result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.3675704\n",
      "}\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Task b0c602dc-c730-43a8-a545-3df3a1d3b8cd result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"mean\": 42.5,\n",
      "      \"std_dev\": 3.14\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.365584\n",
      "}\n",
      "Task 7d9d5bf7-9d1b-4dba-8526-3d866e758a9b result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.3675704\n",
      "}\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Task b0c602dc-c730-43a8-a545-3df3a1d3b8cd result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"mean\": 42.5,\n",
      "      \"std_dev\": 3.14\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.365584\n",
      "}\n",
      "Task 7d9d5bf7-9d1b-4dba-8526-3d866e758a9b result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.3675704\n",
      "}\n",
      "Task be084208-4201-4d35-933d-83e7397ec257 result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424417.365863\n",
      "}\n",
      "Task b0c602dc-c730-43a8-a545-3df3a1d3b8cd result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"mean\": 42.5,\n",
      "      \"std_dev\": 3.14\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.365584\n",
      "}\n",
      "Task 7d9d5bf7-9d1b-4dba-8526-3d866e758a9b result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"size\": [\n",
      "        800,\n",
      "        600\n",
      "      ],\n",
      "      \"format\": \"jpeg\"\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424418.3675704\n",
      "}\n",
      "Task 66191cf4-f263-4bea-92a2-ff9daa5c6cce result: {\n",
      "  \"status\": \"completed\",\n",
      "  \"result\": {\n",
      "    \"success\": true,\n",
      "    \"data\": {\n",
      "      \"mean\": 42.5,\n",
      "      \"std_dev\": 3.14\n",
      "    }\n",
      "  },\n",
      "  \"timestamp\": 1744424420.3684547\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any, Callable, Optional\n",
    "from dataclasses import dataclass\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "# Interfaces\n",
    "class TaskQueue(ABC):\n",
    "    @abstractmethod\n",
    "    def enqueue(self, task: Dict[str, Any]) -> str:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def dequeue(self) -> Optional[Dict[str, Any]]:\n",
    "        pass\n",
    "\n",
    "class ResultStore(ABC):\n",
    "    @abstractmethod\n",
    "    def store_result(self, task_id: str, result: Dict[str, Any]) -> None:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_result(self, task_id: str) -> Optional[Dict[str, Any]]:\n",
    "        pass\n",
    "\n",
    "class Worker(ABC):\n",
    "    @abstractmethod\n",
    "    def process(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class InMemoryQueue(TaskQueue):\n",
    "    def __init__(self):\n",
    "        self._queue = queue.Queue()\n",
    "        self._published_ids = set()\n",
    "    \n",
    "    def enqueue(self, task: Dict[str, Any]) -> str:\n",
    "        task_id = str(uuid.uuid4())\n",
    "        self._queue.put({\"id\": task_id, **task})\n",
    "        self._published_ids.add(task_id)\n",
    "        return task_id\n",
    "    \n",
    "    def dequeue(self) -> Optional[Dict[str, Any]]:\n",
    "        try:\n",
    "            return self._queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "\n",
    "class RedisResultStore(ResultStore):\n",
    "    def __init__(self):\n",
    "        # Simulating Redis with a dict\n",
    "        self._store = {}\n",
    "    \n",
    "    def store_result(self, task_id: str, result: Dict[str, Any]) -> None:\n",
    "        self._store[task_id] = {\n",
    "            \"status\": \"completed\",\n",
    "            \"result\": result,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "    \n",
    "    def get_result(self, task_id: str) -> Optional[Dict[str, Any]]:\n",
    "        return self._store.get(task_id)\n",
    "\n",
    "class TaskWorker(Worker):\n",
    "    def __init__(self, task_handlers: Dict[str, Callable]):\n",
    "        self.handlers = task_handlers\n",
    "    \n",
    "    def process(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        handler = self.handlers.get(task[\"type\"])\n",
    "        if not handler:\n",
    "            return {\"error\": f\"No handler for task type {task['type']}\"}\n",
    "        \n",
    "        try:\n",
    "            result = handler(task[\"payload\"])\n",
    "            return {\"success\": True, \"data\": result}\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "# Composed Distributed Task System\n",
    "class DistributedTaskSystem:\n",
    "    def __init__(\n",
    "        self,\n",
    "        queue: TaskQueue,\n",
    "        result_store: ResultStore,\n",
    "        worker: Worker,\n",
    "        num_workers: int = 3\n",
    "    ):\n",
    "        self.queue = queue\n",
    "        self.result_store = result_store\n",
    "        self.worker = worker\n",
    "        self.workers = []\n",
    "        self._shutdown = False\n",
    "        \n",
    "        for i in range(num_workers):\n",
    "            t = threading.Thread(\n",
    "                target=self._worker_loop,\n",
    "                name=f\"Worker-{i+1}\",\n",
    "                daemon=True\n",
    "            )\n",
    "            self.workers.append(t)\n",
    "    \n",
    "    def start(self) -> None:\n",
    "        for worker in self.workers:\n",
    "            worker.start()\n",
    "    \n",
    "    def shutdown(self) -> None:\n",
    "        self._shutdown = True\n",
    "        for worker in self.workers:\n",
    "            worker.join()\n",
    "    \n",
    "    def _worker_loop(self) -> None:\n",
    "        while not self._shutdown:\n",
    "            task = self.queue.dequeue()\n",
    "            if task is None:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "            \n",
    "            result = self.worker.process(task)\n",
    "            self.result_store.store_result(task[\"id\"], result)\n",
    "    \n",
    "    def submit_task(self, task_type: str, payload: Dict[str, Any]) -> str:\n",
    "        return self.queue.enqueue({\n",
    "            \"type\": task_type,\n",
    "            \"payload\": payload\n",
    "        })\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Define task handlers\n",
    "    def process_image(payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(f\"Processing image: {payload['filename']}\")\n",
    "        time.sleep(1)  # Simulate work\n",
    "        return {\"size\": (800, 600), \"format\": \"jpeg\"}\n",
    "    \n",
    "    def analyze_data(payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(f\"Analyzing dataset: {payload['dataset']}\")\n",
    "        time.sleep(2)  # Simulate work\n",
    "        return {\"mean\": 42.5, \"std_dev\": 3.14}\n",
    "    \n",
    "    # Configure system\n",
    "    system = DistributedTaskSystem(\n",
    "        queue=InMemoryQueue(),\n",
    "        result_store=RedisResultStore(),\n",
    "        worker=TaskWorker({\n",
    "            \"process_image\": process_image,\n",
    "            \"analyze_data\": analyze_data\n",
    "        }),\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    # Start workers\n",
    "    system.start()\n",
    "    \n",
    "    # Submit tasks\n",
    "    tasks = [\n",
    "        (\"process_image\", {\"filename\": \"photo1.jpg\"}),\n",
    "        (\"analyze_data\", {\"dataset\": \"sales_q1\"}),\n",
    "        (\"process_image\", {\"filename\": \"photo2.png\"}),\n",
    "        (\"analyze_data\", {\"dataset\": \"inventory\"})\n",
    "    ]\n",
    "    \n",
    "    task_ids = [system.submit_task(t[0], t[1]) for t in tasks]\n",
    "    \n",
    "    # Monitor results\n",
    "    while True:\n",
    "        all_done = True\n",
    "        for task_id in task_ids:\n",
    "            result = system.result_store.get_result(task_id)\n",
    "            if result is None:\n",
    "                all_done = False\n",
    "                continue\n",
    "            print(f\"Task {task_id} result: {json.dumps(result, indent=2)}\")\n",
    "        \n",
    "        if all_done:\n",
    "            break\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    system.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90940f5-9e3f-4dee-8423-b47533dc4da5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f85bf3-c8dc-48eb-8a6a-3a7daea83a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MQTT broker at mqtt.iot-server.com...\n",
      "Establishing CoAP connection...\n",
      "Sending commands to devices:\n",
      "Sensor1 response: MQTT_ACK:read_temp\n",
      "Sensor2 response: CoAP_RES:GET_STATUS\n",
      "\n",
      "Processing data:\n",
      "Sensor1 parsed: {'temperature': 26.57112620002397, 'humidity': 46.33726584168778, 'voltage': 3.33451292408693}\n",
      "Sensor2 parsed: {'temp': 23.5, 'press': 1013.25, 'light': 780.0}\n",
      "\n",
      "Monitoring devices (wait 2 minutes for potential alerts)...\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-001 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-001 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-001 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: SMS sent for device sensor-002 - Device unhealthy: High temperature\n",
      "ALERT: Email sent for device sensor-002 - Device unhealthy: High temperature\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import time\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "# Interfaces\n",
    "class DeviceProtocol(ABC):\n",
    "    @abstractmethod\n",
    "    def connect(self) -> bool:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def send_command(self, command: str) -> str:\n",
    "        pass\n",
    "\n",
    "class DataParser(ABC):\n",
    "    @abstractmethod\n",
    "    def parse(self, raw_data: str) -> Dict[str, float]:\n",
    "        pass\n",
    "\n",
    "class AlertHandler(ABC):\n",
    "    @abstractmethod\n",
    "    def trigger_alert(self, device_id: str, message: str) -> None:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class MQTTProtocol(DeviceProtocol):\n",
    "    def __init__(self, broker: str):\n",
    "        self.broker = broker\n",
    "        self.connected = False\n",
    "    \n",
    "    def connect(self) -> bool:\n",
    "        print(f\"Connecting to MQTT broker at {self.broker}...\")\n",
    "        time.sleep(0.5)\n",
    "        self.connected = True\n",
    "        return True\n",
    "    \n",
    "    def send_command(self, command: str) -> str:\n",
    "        return f\"MQTT_ACK:{command}\"\n",
    "\n",
    "class CoAPProtocol(DeviceProtocol):\n",
    "    def connect(self) -> bool:\n",
    "        print(\"Establishing CoAP connection...\")\n",
    "        return True\n",
    "    \n",
    "    def send_command(self, command: str) -> str:\n",
    "        return f\"CoAP_RES:{command.upper()}\"\n",
    "\n",
    "class JSONParser(DataParser):\n",
    "    def parse(self, raw_data: str) -> Dict[str, float]:\n",
    "        # Simulate JSON parsing\n",
    "        return {\n",
    "            \"temperature\": random.uniform(20, 30),\n",
    "            \"humidity\": random.uniform(40, 60),\n",
    "            \"voltage\": random.uniform(3.2, 3.8)\n",
    "        }\n",
    "\n",
    "class CSVDataParser(DataParser):\n",
    "    def parse(self, raw_data: str) -> Dict[str, float]:\n",
    "        # Simulate CSV parsing\n",
    "        values = raw_data.split(\",\")\n",
    "        return {\n",
    "            \"temp\": float(values[0]),\n",
    "            \"press\": float(values[1]),\n",
    "            \"light\": float(values[2])\n",
    "        }\n",
    "\n",
    "class EmailAlertHandler(AlertHandler):\n",
    "    def trigger_alert(self, device_id: str, message: str) -> None:\n",
    "        print(f\"ALERT: Email sent for device {device_id} - {message}\")\n",
    "\n",
    "class SMSAlertHandler(AlertHandler):\n",
    "    def trigger_alert(self, device_id: str, message: str) -> None:\n",
    "        print(f\"ALERT: SMS sent for device {device_id} - {message}\")\n",
    "\n",
    "# Composed IoT Device\n",
    "class IoTDevice:\n",
    "    def __init__(\n",
    "        self,\n",
    "        device_id: str,\n",
    "        protocol: DeviceProtocol,\n",
    "        parser: DataParser,\n",
    "        alert_handlers: Optional[List[AlertHandler]] = None,\n",
    "        health_check_interval: int = 60\n",
    "    ):\n",
    "        self.device_id = device_id\n",
    "        self.protocol = protocol\n",
    "        self.parser = parser\n",
    "        self.alert_handlers = alert_handlers or []\n",
    "        self.health_check_interval = health_check_interval\n",
    "        self._data_queue = Queue()\n",
    "        self._monitor_thread = Thread(target=self._monitor_device, daemon=True)\n",
    "    \n",
    "    def connect(self) -> bool:\n",
    "        return self.protocol.connect()\n",
    "    \n",
    "    def send_command(self, command: str) -> str:\n",
    "        return self.protocol.send_command(command)\n",
    "    \n",
    "    def process_data(self, raw_data: str) -> Dict[str, float]:\n",
    "        return self.parser.parse(raw_data)\n",
    "    \n",
    "    def add_alert_handler(self, handler: AlertHandler) -> None:\n",
    "        self.alert_handlers.append(handler)\n",
    "    \n",
    "    def start_monitoring(self) -> None:\n",
    "        self._monitor_thread.start()\n",
    "    \n",
    "    def _monitor_device(self) -> None:\n",
    "        while True:\n",
    "            # Simulate device monitoring\n",
    "            time.sleep(self.health_check_interval)\n",
    "            status = self._check_device_health()\n",
    "            \n",
    "            if not status[\"healthy\"]:\n",
    "                for handler in self.alert_handlers:\n",
    "                    handler.trigger_alert(\n",
    "                        self.device_id,\n",
    "                        f\"Device unhealthy: {status['message']}\"\n",
    "                    )\n",
    "    \n",
    "    def _check_device_health(self) -> Dict[str, Any]:\n",
    "        # Simulate health check (20% chance of failure)\n",
    "        if random.random() < 0.2:\n",
    "            return {\"healthy\": False, \"message\": \"High temperature\"}\n",
    "        return {\"healthy\": True, \"message\": \"OK\"}\n",
    "\n",
    "# Device Manager\n",
    "class IoTDeviceManager:\n",
    "    def __init__(self):\n",
    "        self.devices: Dict[str, IoTDevice] = {}\n",
    "    \n",
    "    def register_device(self, device: IoTDevice) -> None:\n",
    "        if device.connect():\n",
    "            self.devices[device.device_id] = device\n",
    "            device.start_monitoring()\n",
    "    \n",
    "    def send_command_to_device(self, device_id: str, command: str) -> Optional[str]:\n",
    "        device = self.devices.get(device_id)\n",
    "        if device:\n",
    "            return device.send_command(command)\n",
    "        return None\n",
    "    \n",
    "    def get_device_status(self) -> Dict[str, Dict[str, Any]]:\n",
    "        return {\n",
    "            dev_id: {\n",
    "                \"connected\": True,\n",
    "                \"last_seen\": time.time()\n",
    "            }\n",
    "            for dev_id in self.devices.keys()\n",
    "        }\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Create device manager\n",
    "    manager = IoTDeviceManager()\n",
    "\n",
    "    # Create devices with different configurations\n",
    "    sensor1 = IoTDevice(\n",
    "        device_id=\"sensor-001\",\n",
    "        protocol=MQTTProtocol(\"mqtt.iot-server.com\"),\n",
    "        parser=JSONParser(),\n",
    "        alert_handlers=[EmailAlertHandler()]\n",
    "    )\n",
    "\n",
    "    sensor2 = IoTDevice(\n",
    "        device_id=\"sensor-002\",\n",
    "        protocol=CoAPProtocol(),\n",
    "        parser=CSVDataParser(),\n",
    "        alert_handlers=[SMSAlertHandler(), EmailAlertHandler()],\n",
    "        health_check_interval=30\n",
    "    )\n",
    "\n",
    "    # Register devices\n",
    "    manager.register_device(sensor1)\n",
    "    manager.register_device(sensor2)\n",
    "\n",
    "    # Simulate operations\n",
    "    print(\"Sending commands to devices:\")\n",
    "    print(\"Sensor1 response:\", manager.send_command_to_device(\"sensor-001\", \"read_temp\"))\n",
    "    print(\"Sensor2 response:\", manager.send_command_to_device(\"sensor-002\", \"get_status\"))\n",
    "\n",
    "    # Process sample data\n",
    "    print(\"\\nProcessing data:\")\n",
    "    print(\"Sensor1 parsed:\", sensor1.process_data('{\"temp\":22.5,\"humidity\":55}'))\n",
    "    print(\"Sensor2 parsed:\", sensor2.process_data(\"23.5,1013.25,780\"))\n",
    "\n",
    "    # Monitor for alerts (run for 2 minutes)\n",
    "    print(\"\\nMonitoring devices (wait 2 minutes for potential alerts)...\")\n",
    "    time.sleep(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ea386-d404-48cc-a74a-9f154027d558",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### [19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aa89ad6-f9af-47fb-9e9a-29a31034a8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscribed to BTCUSDT market data\n",
      "Starting trading engine...\n",
      "Connecting to Binance WebSocket...\n",
      "Sent order order_1744425590522 to Alpaca\n",
      "Executed order order_1744425590522\n",
      "Sent order order_1744425590826 to Alpaca\n",
      "Executed order order_1744425590826\n",
      "Sent order order_1744425591128 to Alpaca\n",
      "Executed order order_1744425591128\n",
      "Sent order order_1744425591332 to Alpaca\n",
      "Executed order order_1744425591332\n",
      "Sent order order_1744425592140 to Alpaca\n",
      "Executed order order_1744425592140\n",
      "Sent order order_1744425592946 to Alpaca\n",
      "Executed order order_1744425592946\n",
      "Sent order order_1744425594162 to Alpaca\n",
      "Executed order order_1744425594162\n",
      "Sent order order_1744425594566 to Alpaca\n",
      "Executed order order_1744425594566\n",
      "Sent order order_1744425594869 to Alpaca\n",
      "Executed order order_1744425594869\n",
      "Sent order order_1744425595074 to Alpaca\n",
      "Executed order order_1744425595074\n",
      "Sent order order_1744425595175 to Alpaca\n",
      "Executed order order_1744425595175\n",
      "Sent order order_1744425595278 to Alpaca\n",
      "Executed order order_1744425595278\n",
      "Sent order order_1744425595682 to Alpaca\n",
      "Executed order order_1744425595682\n",
      "Sent order order_1744425595987 to Alpaca\n",
      "Executed order order_1744425595987\n",
      "Sent order order_1744425596999 to Alpaca\n",
      "Executed order order_1744425596999\n",
      "Sent order order_1744425597203 to Alpaca\n",
      "Executed order order_1744425597203\n",
      "Sent order order_1744425597305 to Alpaca\n",
      "Executed order order_1744425597305\n",
      "Sent order order_1744425597609 to Alpaca\n",
      "Executed order order_1744425597609\n",
      "Sent order order_1744425597812 to Alpaca\n",
      "Executed order order_1744425597812\n",
      "Sent order order_1744425598520 to Alpaca\n",
      "Executed order order_1744425598520\n",
      "Sent order order_1744425598621 to Alpaca\n",
      "Executed order order_1744425598621\n",
      "Sent order order_1744425598724 to Alpaca\n",
      "Executed order order_1744425598724\n",
      "Sent order order_1744425599028 to Alpaca\n",
      "Executed order order_1744425599028\n",
      "Sent order order_1744425599534 to Alpaca\n",
      "Executed order order_1744425599534\n",
      "Sent order order_1744425599838 to Alpaca\n",
      "Executed order order_1744425599838\n",
      "Sent order order_1744425600043 to Alpaca\n",
      "Executed order order_1744425600043\n",
      "Sent order order_1744425600144 to Alpaca\n",
      "Executed order order_1744425600144\n",
      "Sent order order_1744425600448 to Alpaca\n",
      "Executed order order_1744425600448\n",
      "Sent order order_1744425600752 to Alpaca\n",
      "Executed order order_1744425600752\n",
      "Sent order order_1744425601057 to Alpaca\n",
      "Executed order order_1744425601057\n",
      "Sent order order_1744425601664 to Alpaca\n",
      "Executed order order_1744425601664\n",
      "Sent order order_1744425601970 to Alpaca\n",
      "Executed order order_1744425601970\n",
      "Sent order order_1744425602678 to Alpaca\n",
      "Executed order order_1744425602678\n",
      "Sent order order_1744425602983 to Alpaca\n",
      "Executed order order_1744425602983\n",
      "Sent order order_1744425603286 to Alpaca\n",
      "Executed order order_1744425603286\n",
      "Sent order order_1744425603388 to Alpaca\n",
      "Executed order order_1744425603388\n",
      "Sent order order_1744425603791 to Alpaca\n",
      "Executed order order_1744425603791\n",
      "Sent order order_1744425603892 to Alpaca\n",
      "Executed order order_1744425603892\n",
      "Sent order order_1744425604096 to Alpaca\n",
      "Executed order order_1744425604096\n",
      "Sent order order_1744425604502 to Alpaca\n",
      "Executed order order_1744425604502\n",
      "Sent order order_1744425604814 to Alpaca\n",
      "Executed order order_1744425604814\n",
      "Sent order order_1744425605018 to Alpaca\n",
      "Executed order order_1744425605018\n",
      "Sent order order_1744425605119 to Alpaca\n",
      "Executed order order_1744425605119\n",
      "Sent order order_1744425605424 to Alpaca\n",
      "Executed order order_1744425605424\n",
      "Sent order order_1744425605526 to Alpaca\n",
      "Executed order order_1744425605526\n",
      "Sent order order_1744425605729 to Alpaca\n",
      "Executed order order_1744425605729\n",
      "Sent order order_1744425606539 to Alpaca\n",
      "Executed order order_1744425606539\n",
      "Sent order order_1744425607348 to Alpaca\n",
      "Executed order order_1744425607348\n",
      "Sent order order_1744425607956 to Alpaca\n",
      "Executed order order_1744425607956\n",
      "Sent order order_1744425608058 to Alpaca\n",
      "Executed order order_1744425608058\n",
      "Sent order order_1744425608160 to Alpaca\n",
      "Executed order order_1744425608160\n",
      "Sent order order_1744425609069 to Alpaca\n",
      "Executed order order_1744425609069\n",
      "Sent order order_1744425609374 to Alpaca\n",
      "Executed order order_1744425609374\n",
      "Sent order order_1744425610588 to Alpaca\n",
      "Executed order order_1744425610588\n",
      "Sent order order_1744425610792 to Alpaca\n",
      "Executed order order_1744425610792\n",
      "Sent order order_1744425610894 to Alpaca\n",
      "Executed order order_1744425610894\n",
      "Sent order order_1744425611197 to Alpaca\n",
      "Executed order order_1744425611197\n",
      "Sent order order_1744425611805 to Alpaca\n",
      "Executed order order_1744425611805\n",
      "Sent order order_1744425611907 to Alpaca\n",
      "Executed order order_1744425611907\n",
      "Sent order order_1744425612009 to Alpaca\n",
      "Executed order order_1744425612009\n",
      "Sent order order_1744425612111 to Alpaca\n",
      "Executed order order_1744425612111\n",
      "Sent order order_1744425612214 to Alpaca\n",
      "Executed order order_1744425612214\n",
      "Sent order order_1744425612519 to Alpaca\n",
      "Executed order order_1744425612519\n",
      "Sent order order_1744425612722 to Alpaca\n",
      "Executed order order_1744425612722\n",
      "Sent order order_1744425613026 to Alpaca\n",
      "Executed order order_1744425613026\n",
      "Sent order order_1744425613633 to Alpaca\n",
      "Executed order order_1744425613633\n",
      "Sent order order_1744425613837 to Alpaca\n",
      "Executed order order_1744425613837\n",
      "Sent order order_1744425614644 to Alpaca\n",
      "Executed order order_1744425614644\n",
      "Sent order order_1744425614848 to Alpaca\n",
      "Executed order order_1744425614848\n",
      "Sent order order_1744425615251 to Alpaca\n",
      "Executed order order_1744425615251\n",
      "Sent order order_1744425615555 to Alpaca\n",
      "Executed order order_1744425615555\n",
      "Sent order order_1744425616564 to Alpaca\n",
      "Executed order order_1744425616564\n",
      "Sent order order_1744425616665 to Alpaca\n",
      "Executed order order_1744425616665\n",
      "Sent order order_1744425616872 to Alpaca\n",
      "Executed order order_1744425616872\n",
      "Sent order order_1744425617478 to Alpaca\n",
      "Executed order order_1744425617478\n",
      "Sent order order_1744425617684 to Alpaca\n",
      "Executed order order_1744425617684\n",
      "Sent order order_1744425617785 to Alpaca\n",
      "Executed order order_1744425617785\n",
      "Trading engine stopped\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import threading\n",
    "import queue\n",
    "import random\n",
    "import time\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "\n",
    "# Interfaces\n",
    "class MarketDataFeed(ABC):\n",
    "    @abstractmethod\n",
    "    def connect(self) -> bool:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def subscribe(self, symbol: str) -> None:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_next_tick(self) -> Optional[Dict[str, Any]]:\n",
    "        pass\n",
    "\n",
    "class OrderExecution(ABC):\n",
    "    @abstractmethod\n",
    "    def send_order(self, order: Dict[str, Any]) -> str:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def cancel_order(self, order_id: str) -> bool:\n",
    "        pass\n",
    "\n",
    "class RiskManager(ABC):\n",
    "    @abstractmethod\n",
    "    def check_order(self, order: Dict[str, Any], portfolio: Dict[str, Any]) -> Tuple[bool, str]:\n",
    "        pass\n",
    "\n",
    "class Strategy(ABC):\n",
    "    @abstractmethod\n",
    "    def on_market_data(self, tick: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        pass\n",
    "\n",
    "# Implementations\n",
    "class BinanceMarketData(MarketDataFeed):\n",
    "    def __init__(self):\n",
    "        self._connected = False\n",
    "        self._symbols = set()\n",
    "        self._tick_queue = queue.Queue()\n",
    "    \n",
    "    def connect(self) -> bool:\n",
    "        print(\"Connecting to Binance WebSocket...\")\n",
    "        self._connected = True\n",
    "        return True\n",
    "    \n",
    "    def subscribe(self, symbol: str) -> None:\n",
    "        self._symbols.add(symbol)\n",
    "        print(f\"Subscribed to {symbol} market data\")\n",
    "    \n",
    "    def get_next_tick(self) -> Optional[Dict[str, Any]]:\n",
    "        if not self._connected:\n",
    "            return None\n",
    "        \n",
    "        # Simulate market data\n",
    "        if random.random() > 0.7:  # 30% chance of new tick\n",
    "            symbol = random.choice(list(self._symbols))\n",
    "            return {\n",
    "                \"symbol\": symbol,\n",
    "                \"price\": Decimal(random.uniform(100, 200)).quantize(Decimal(\"0.01\")),\n",
    "                \"quantity\": Decimal(random.uniform(1, 10)).quantize(Decimal(\"0.0001\")),\n",
    "                \"timestamp\": int(time.time() * 1000)\n",
    "            }\n",
    "        return None\n",
    "\n",
    "class AlpacaExecution(OrderExecution):\n",
    "    def __init__(self):\n",
    "        self._orders = {}\n",
    "    \n",
    "    def send_order(self, order: Dict[str, Any]) -> str:\n",
    "        order_id = f\"order_{int(time.time() * 1000)}\"\n",
    "        self._orders[order_id] = {\n",
    "            **order,\n",
    "            \"status\": \"filled\" if random.random() > 0.1 else \"rejected\"\n",
    "        }\n",
    "        print(f\"Sent order {order_id} to Alpaca\")\n",
    "        return order_id\n",
    "    \n",
    "    def cancel_order(self, order_id: str) -> bool:\n",
    "        if order_id in self._orders:\n",
    "            self._orders[order_id][\"status\"] = \"cancelled\"\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "class BasicRiskManager(RiskManager):\n",
    "    def __init__(self, max_position_size: Decimal = Decimal(\"10000\")):\n",
    "        self.max_position_size = max_position_size\n",
    "    \n",
    "    def check_order(self, order: Dict[str, Any], portfolio: Dict[str, Any]) -> Tuple[bool, str]:\n",
    "        notional = order[\"price\"] * order[\"quantity\"]\n",
    "        if notional > self.max_position_size:\n",
    "            return False, f\"Order size {notional} exceeds max {self.max_position_size}\"\n",
    "        return True, \"\"\n",
    "\n",
    "\n",
    "class MeanReversionStrategy(Strategy):\n",
    "    def __init__(self, symbol: str, lookback: int = 10):\n",
    "        self.symbol = symbol\n",
    "        self.lookback = lookback\n",
    "        self.price_history = []\n",
    "        # Set decimal precision\n",
    "        getcontext().prec = 6\n",
    "    \n",
    "    def on_market_data(self, tick: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        if tick[\"symbol\"] != self.symbol:\n",
    "            return None\n",
    "        \n",
    "        # Convert price to Decimal for consistent arithmetic\n",
    "        current_price = Decimal(str(tick[\"price\"]))\n",
    "        self.price_history.append(current_price)\n",
    "        \n",
    "        if len(self.price_history) > self.lookback:\n",
    "            self.price_history.pop(0)\n",
    "        \n",
    "        if len(self.price_history) == self.lookback:\n",
    "            avg_price = sum(self.price_history) / Decimal(self.lookback)\n",
    "            \n",
    "            if current_price < avg_price * Decimal(\"0.98\"):\n",
    "                return {\n",
    "                    \"symbol\": self.symbol,\n",
    "                    \"side\": \"BUY\",\n",
    "                    \"quantity\": Decimal(\"1\"),\n",
    "                    \"type\": \"LIMIT\",\n",
    "                    \"price\": current_price\n",
    "                }\n",
    "            elif current_price > avg_price * Decimal(\"1.02\"):\n",
    "                return {\n",
    "                    \"symbol\": self.symbol,\n",
    "                    \"side\": \"SELL\",\n",
    "                    \"quantity\": Decimal(\"1\"),\n",
    "                    \"type\": \"LIMIT\",\n",
    "                    \"price\": current_price\n",
    "                }\n",
    "        return None\n",
    "\n",
    "\n",
    "# Composed Trading Engine\n",
    "class TradingEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_feeds: List[MarketDataFeed],\n",
    "        execution: OrderExecution,\n",
    "        risk_manager: RiskManager,\n",
    "        strategies: List[Strategy],\n",
    "        portfolio: Dict[str, Any]\n",
    "    ):\n",
    "        self.data_feeds = data_feeds\n",
    "        self.execution = execution\n",
    "        self.risk_manager = risk_manager\n",
    "        self.strategies = strategies\n",
    "        self.portfolio = portfolio\n",
    "        self._running = False\n",
    "        self._engine_thread = threading.Thread(target=self._run_engine, daemon=True)\n",
    "    \n",
    "    def start(self) -> None:\n",
    "        print(\"Starting trading engine...\")\n",
    "        for feed in self.data_feeds:\n",
    "            feed.connect()\n",
    "        self._running = True\n",
    "        self._engine_thread.start()\n",
    "    \n",
    "    def stop(self) -> None:\n",
    "        self._running = False\n",
    "        self._engine_thread.join()\n",
    "        print(\"Trading engine stopped\")\n",
    "    \n",
    "    def _run_engine(self) -> None:\n",
    "        while self._running:\n",
    "            # Process market data\n",
    "            for feed in self.data_feeds:\n",
    "                tick = feed.get_next_tick()\n",
    "                if tick:\n",
    "                    self._process_tick(tick)\n",
    "            \n",
    "            time.sleep(0.1)  # Prevent CPU overload\n",
    "    \n",
    "    def _process_tick(self, tick: Dict[str, Any]) -> None:\n",
    "        # Run strategies\n",
    "        for strategy in self.strategies:\n",
    "            order = strategy.on_market_data(tick)\n",
    "            if order:\n",
    "                # Check risk\n",
    "                approved, reason = self.risk_manager.check_order(order, self.portfolio)\n",
    "                if approved:\n",
    "                    order_id = self.execution.send_order(order)\n",
    "                    print(f\"Executed order {order_id}\")\n",
    "                else:\n",
    "                    print(f\"Order rejected: {reason}\")\n",
    "\n",
    "# Usage Example\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup components\n",
    "    binance_feed = BinanceMarketData()\n",
    "    binance_feed.subscribe(\"BTCUSDT\")\n",
    "    \n",
    "    alpaca_exec = AlpacaExecution()\n",
    "    risk_mgr = BasicRiskManager(max_position_size=Decimal(\"5000\"))\n",
    "    strategy = MeanReversionStrategy(symbol=\"BTCUSDT\")\n",
    "    \n",
    "    # Create trading engine\n",
    "    engine = TradingEngine(\n",
    "        data_feeds=[binance_feed],\n",
    "        execution=alpaca_exec,\n",
    "        risk_manager=risk_mgr,\n",
    "        strategies=[strategy],\n",
    "        portfolio={\"USD\": Decimal(\"10000\"), \"BTC\": Decimal(\"0\")}\n",
    "    )\n",
    "    \n",
    "    # Run for 30 seconds\n",
    "    try:\n",
    "        engine.start()\n",
    "        time.sleep(30)\n",
    "    finally:\n",
    "        engine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267c2f2-bc2c-4c93-b496-6aa7eb67c7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
