{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764928ba-868a-48de-915c-bfb5399e1d01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### encapsulating using polymorphism\n",
    "`Favor Composition Over Inheritance` principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9119a66-9c1b-4abe-bb48-96fab9b54ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5687a846-1042-4000-8e2d-ad5844ecd89d",
   "metadata": {},
   "source": [
    "### test RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e5d48-0f60-4ff6-8332-8af8a5eaa897",
   "metadata": {},
   "source": [
    "#### Retrieval augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653242e-2da1-403a-b5ac-e8fdaf871d42",
   "metadata": {},
   "source": [
    "[langchain.com](https://www.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076f2f6-8f79-4391-a1b0-ee4194ec7e2d",
   "metadata": {},
   "source": [
    "```bash\n",
    "uv add langchain langchain_community faiss-cpu sentence-transformers transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a696b3f-cb25-4507-aff1-bd42e9693038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv add ipywidgets\n",
    "\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca6afd9-d70e-4085-9a18-13428b4f919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading zip file...\n",
      "Download complete!\n",
      "Extracting files...\n",
      "Files extracted to: asia_txt_files\n",
      "Extracted files:\n",
      "['Malaysia.txt', 'Mongolia.txt', 'Philippines.txt', 'South_Korea.txt', 'Thailand.txt', 'Japan.txt', 'Taiwan.txt', 'Indonesia.txt', 'Vietnam.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "zip_url = \"https://github.com/gakudo-ai/open-datasets/raw/refs/heads/main/asia_documents.zip\"\n",
    "zip_path = \"asia_documents.zip\"\n",
    "extract_folder = \"asia_txt_files\"\n",
    "\n",
    "print(\"Downloading zip file...\")\n",
    "urllib.request.urlretrieve(zip_url, zip_path)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "print(\"Extracting files...\")\n",
    "os.makedirs(extract_folder, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Files extracted to: {extract_folder}\")\n",
    "\n",
    "print(\"Extracted files:\")\n",
    "print(os.listdir(extract_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3daebf-a9cb-42bd-8672-942e3b0e4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv add -U langchain-huggingface\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "folder_path = \"asia_txt_files\"\n",
    "\n",
    "documents = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d3602a-c9e3-4f8f-a68d-d32270807e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=\"gpt2\", device=0, max_new_tokens=200)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e284c77e-fa53-44db-9f48-0e38f06b63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"Answer the following question based on the provided context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},  # Pass the prompt here\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2474f71-1467-4085-8e9c-3f224609c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_to_max_tokens(text, max_tokens=500):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) > max_tokens:\n",
    "        return \" \".join(tokens[:max_tokens])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8bafa8-944a-4241-a09f-198064e2cffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Answer the following question based on the provided context:\n",
      "Vietnam is a Southeast Asian country known for its rich history, diverse landscapes, and delicious cuisine. Hanoi and Ho Chi Minh City are its major urban centers, each with a unique character. Ha Long Bay’s limestone karsts and the Mekong Delta’s floating markets are famous geographical highlights. Vietnamese culture is deeply influenced by Confucian values, French colonial heritage, and indigenous traditions.\n",
      "\n",
      "Thailand is a Southeast Asian country famous for its tropical beaches, ornate temples, and bustling street food culture. Bangkok, the capital, is known for its vibrant nightlife and historical sites like the Grand Palace and Wat Arun. Northern Thailand features mountainous landscapes and cultural cities like Chiang Mai, while the south offers world-renowned islands such as Phuket and Koh Samui.\n",
      "\n",
      "Malaysia is a diverse country in Southeast Asia, divided into Peninsular Malaysia and Malaysian Borneo. Kuala Lumpur, the capital, features the iconic Petronas Towers. The country is known for its multicultural society, rainforests, and beautiful islands such as Langkawi. Malaysian cuisine blends Malay, Chinese, and Indian influences, making it one of the most flavorful in the region.\n",
      "\n",
      "Japan is an island nation in East Asia, known for its unique blend of ancient traditions and cutting-edge technology. It has a rich cultural heritage, including tea ceremonies, sumo wrestling, and kabuki theater. Geographically, Japan consists of four main islands and numerous smaller ones, featuring mountains, forests, and a rugged coastline. Mount Fuji is its most iconic peak. Major cities include Tokyo, Kyoto, and Osaka, each offering distinct experiences from historical temples to modern skyscrapers.\n",
      "\n",
      "Question: What are the best Asian cuisine dishes?\n",
      "Answer: The dishes mentioned in this order include the following:\n",
      "\n",
      "Fried rice in green, roasted chili sauce in green & green rice sauce in red. Fresh veggies such as vegetables, green beans, onions, onions, celery, mushrooms, and tomatoes are also available from a wide range of vendors. Vegetables are usually cooked using olive oil or water.\n",
      "\n",
      "Takoyaki chicken in bright orange, cooked green beans. Chicken noodles are cooked using olive oil or water.\n",
      "\n",
      "Eve's noodles in red, fried. You will also find this meal using regular rice noodles.\n",
      "\n",
      "Cultured or prepared hot rice. A combination of sesame oil and chili powder is baked into chili.\n",
      "\n",
      "The following choices are considered extremely nutritious:\n",
      "\n",
      "Serves 8\n",
      "\n",
      "4 portions\n",
      "\n",
      "1 piece\n",
      "\n",
      "1 tablespoon soy sauce\n",
      "\n",
      "1 tablespoon vegetable oil\n",
      "\n",
      "1 teaspoon turmeric\n",
      "\n",
      "1 teaspoon curry powder\n",
      "\n",
      "1 tablespoon soy sauce\n",
      "\n",
      "Prerequisites\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the best Asian cuisine dishes?\"\n",
    "\n",
    "# Use `invoke` instead of `get_relevant_documents`\n",
    "retrieved_docs = retriever.invoke(query)[:1]  # Top-1 document\n",
    "context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "context = truncate_to_max_tokens(context, max_tokens=500)\n",
    "\n",
    "# Use `invoke` instead of `run`\n",
    "response = retrieval_qa.invoke({\"query\": query})\n",
    "print(\"Answer:\", response[\"result\"])  # Access the result via [\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e928d0-8ad5-4671-93f7-37d8ae676c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c34a87b9-3726-4323-8296-dd7268449c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('.', 'mohsen.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c70d27c4-c72a-49d2-897e-6ea6f26913f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_texts = TextLoader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c62e24-661f-4d38-bd7c-f2bd5703609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './mohsen.txt'}, page_content='Mohsen Moghimbegloo\\n\\n0935000000\\n\\nPython developer. I work it while 8 years.\\nI will make AI soulusion for all of people.\\n\\nEnd test\\n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_texts.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c473246-0ae2-417f-9c8c-931d1f9d85ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
